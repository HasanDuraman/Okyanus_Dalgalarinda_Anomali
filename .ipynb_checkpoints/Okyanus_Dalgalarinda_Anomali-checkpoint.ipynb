{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeeee94d",
   "metadata": {},
   "source": [
    "##  Setup Environment\n",
    "You can use conda for this assignment.\n",
    "\n",
    "\n",
    "### Steps\n",
    "```bash\n",
    "# Create and activate a fresh environment (Python 3.13)\n",
    "conda create -n vm_env python=3.13\n",
    "conda activate vm_env\n",
    "\n",
    "# Go to the project folder and install dependencies\n",
    "cd Okyanus_Dalgalarinda_Anomali\n",
    "pip install -r Requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f317cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# =======================================================\n",
    "# 1) NOAA Veri İndirme (Sabit Genişlikli Okuma - FWF)\n",
    "# =======================================================\n",
    "print(\"Veri indiriliyor ve işleniyor...\")\n",
    "\n",
    "url = \"https://www.ndbc.noaa.gov/data/realtime2/46047.txt\"\n",
    "\n",
    "# Senin belirttiğin güvenli sütun aralıkları\n",
    "colspecs = [\n",
    "    (0, 4),   # YYYY\n",
    "    (5, 7),   # MM\n",
    "    (8, 10),  # DD\n",
    "    (11, 13), # hh\n",
    "    (14, 16), # mm\n",
    "    (17, 21), # WD\n",
    "    (22, 26), # WSPD\n",
    "    (27, 31), # GST\n",
    "    (32, 37), # WVHT\n",
    "    (38, 42), # DPD\n",
    "    (43, 47), # APD\n",
    "    (48, 52), # MWD\n",
    "    (53, 59), # PRES\n",
    "    (60, 66), # ATMP\n",
    "    (67, 73), # WTMP\n",
    "    (74, 80), # DEWP\n",
    "    (81, 84), # VIS\n",
    "    (85, 88), # PTDY\n",
    "    (89, 92)  # TIDE\n",
    "]\n",
    "\n",
    "names = [\n",
    "    \"YY\",\"MM\",\"DD\",\"hh\",\"mm\",\"WD\",\"WSPD\",\"GST\",\"WVHT\",\"DPD\",\n",
    "    \"APD\",\"MWD\",\"PRES\",\"ATMP\",\"WTMP\",\"DEWP\",\"VIS\",\"PTDY\",\"TIDE\"\n",
    "]\n",
    "\n",
    "# NOAA'da eksik veriler \"MM\", \"99.0\", \"999\" vb. olabilir. Hepsini yakalıyoruz.\n",
    "missing_values = [\"MM\", \"99.0\", \"99.00\", \"999.0\", \"999\", \"nan\"]\n",
    "\n",
    "df = pd.read_fwf(\n",
    "    url, \n",
    "    colspecs=colspecs, \n",
    "    names=names, \n",
    "    skiprows=[0, 1],       # İlk iki satır başlık ve birim, atlıyoruz\n",
    "    na_values=missing_values # Eksik verileri NaN yap\n",
    ")\n",
    "\n",
    "# ---- Tarih Formatını Oluşturma ----\n",
    "# Verileri stringe çevirip birleştiriyoruz\n",
    "df['Time'] = pd.to_datetime(\n",
    "    df['YY'].astype(str) + '-' +\n",
    "    df['MM'].astype(str).str.zfill(2) + '-' +\n",
    "    df['DD'].astype(str).str.zfill(2) + ' ' +\n",
    "    df['hh'].astype(str).str.zfill(2) + ':' +\n",
    "    df['mm'].astype(str).str.zfill(2),\n",
    "    errors='coerce' # Hatalı tarih olursa NaT yap\n",
    ")\n",
    "\n",
    "# Geçersiz tarihleri temizle ve index yap\n",
    "df = df.dropna(subset=['Time'])\n",
    "df = df.set_index('Time')\n",
    "\n",
    "# Analiz için gerekli sütunları seç (Hs, Tp, WSPD)\n",
    "df_analiz = df[['WVHT', 'DPD', 'WSPD']].copy()\n",
    "df_analiz.rename(columns={\"WVHT\": \"Hs\", \"DPD\": \"Tp\", \"WSPD\": \"WindSpeed\"}, inplace=True)\n",
    "\n",
    "# Veri tiplerini sayısal yap (garanti olsun)\n",
    "df_analiz = df_analiz.astype(float)\n",
    "\n",
    "# =======================================================\n",
    "# 2) Eksik Değerleri Doldur + Gürültü Azaltma\n",
    "# =======================================================\n",
    "\n",
    "# Lineer enterpolasyon\n",
    "df_analiz = df_analiz.interpolate(method='linear')\n",
    "# Baştaki/sondaki boşlukları doldur (Python 3.13 uyumlu)\n",
    "df_analiz = df_analiz.ffill().bfill()\n",
    "\n",
    "# Rolling Median (Gürültü filtresi)\n",
    "df_analiz = df_analiz.rolling(window=3, center=True).median()\n",
    "df_analiz = df_analiz.dropna()\n",
    "\n",
    "print(f\"İşlenen veri sayısı: {len(df_analiz)} satır.\")\n",
    "\n",
    "# =======================================================\n",
    "# 3) Z-score Normalizasyonu\n",
    "# =======================================================\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled = scaler.fit_transform(df_analiz)\n",
    "df_scaled = pd.DataFrame(scaled, index=df_analiz.index, columns=df_analiz.columns)\n",
    "\n",
    "# =======================================================\n",
    "# 4) Görselleştirme 1: Zaman Serisi\n",
    "# =======================================================\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(df_analiz.index, df_analiz['Hs'], label=\"Hs (m)\", color='#1f77b4')\n",
    "plt.title(\"Okyanus Dalga Yüksekliği (Hs) - Zaman Serisi\")\n",
    "plt.xlabel(\"Tarih\")\n",
    "plt.ylabel(\"Hs (m)\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show() # Notebook'ta görmek için\n",
    "\n",
    "# =======================================================\n",
    "# 5) Görselleştirme 2: FFT Spektral Analizi\n",
    "# =======================================================\n",
    "\n",
    "hs_detrended = df_analiz['Hs'] - df_analiz['Hs'].mean()\n",
    "fft_vals = np.abs(np.fft.rfft(hs_detrended))\n",
    "fft_freq = np.fft.rfftfreq(len(hs_detrended), d=1.0/6.0) # 10dk veri -> saatte 6 örnek\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(fft_freq, fft_vals, color='purple')\n",
    "plt.title(\"FFT Spektrumu (Dalga Enerjisi)\")\n",
    "plt.xlabel(\"Frekans (Saat başı döngü)\")\n",
    "plt.ylabel(\"Genlik\")\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =======================================================\n",
    "# 6) Isolation Forest Anomali Tespiti\n",
    "# =======================================================\n",
    "\n",
    "isf = IsolationForest(contamination=0.05, random_state=42)\n",
    "df_analiz['anomaly_if'] = isf.fit_predict(df_scaled)\n",
    "df_analiz['score_if'] = isf.decision_function(df_scaled)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(df_analiz.index, df_analiz['Hs'], label=\"Normal Dalga\", color='gray', alpha=0.5)\n",
    "# Anomalileri kırmızı noktalarla işaretle\n",
    "anomalies = df_analiz[df_analiz['anomaly_if'] == -1]\n",
    "plt.scatter(anomalies.index, anomalies['Hs'], color='red', label='Tespit Edilen Anomali', s=20, zorder=5)\n",
    "\n",
    "plt.title(\"Isolation Forest - Fırtına Anomalisi Tespiti\")\n",
    "plt.xlabel(\"Tarih\")\n",
    "plt.ylabel(\"Hs (m)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =======================================================\n",
    "# 7) DBSCAN Clustering (PCA ile)\n",
    "# =======================================================\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X2 = pca.fit_transform(df_scaled)\n",
    "\n",
    "# DBSCAN parametreleri veriye göre ayarlanabilir\n",
    "db = DBSCAN(eps=0.3, min_samples=5).fit(X2)\n",
    "labels = db.labels_\n",
    "\n",
    "plt.figure(figsize=(7, 5))\n",
    "scatter = plt.scatter(X2[:, 0], X2[:, 1], c=labels, cmap='viridis', s=15, alpha=0.7)\n",
    "plt.title(\"DBSCAN Kümeleme (PCA İndirgeme)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.colorbar(scatter, label='Küme ID')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# =======================================================\n",
    "# 8) ROC Eğrisi (Performans Değerlendirme)\n",
    "# =======================================================\n",
    "\n",
    "# Basit ground truth varsayımı: %90 üzerindeki dalgaları \"fırtına\" kabul et\n",
    "true_labels = (df_analiz['Hs'] > df_analiz['Hs'].quantile(0.90)).astype(int)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(true_labels, -df_analiz['score_if'])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"AUC = {roc_auc:.3f}\")\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve (Başarım Ölçümü)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Tüm işlemler başarıyla tamamlandı.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
